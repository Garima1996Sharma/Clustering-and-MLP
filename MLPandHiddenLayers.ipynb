{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2cc38c7",
   "metadata": {},
   "source": [
    "## 1) Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf7404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.400628</td>\n",
       "      <td>-1.062722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.572726</td>\n",
       "      <td>1.030960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.397654</td>\n",
       "      <td>-0.564270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.489704</td>\n",
       "      <td>1.137081</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.761848</td>\n",
       "      <td>1.191341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  class\n",
       "0  1.400628 -1.062722      1\n",
       "1  1.572726  1.030960      0\n",
       "2 -0.397654 -0.564270      2\n",
       "3 -0.489704  1.137081      2\n",
       "4  1.761848  1.191341      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "df = pd.read_csv(\"dataset4.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "711afa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   feature1  500 non-null    float64\n",
      " 1   feature2  500 non-null    float64\n",
      " 2   class     500 non-null    int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 11.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518ad6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      2\n",
       "3      2\n",
       "4      0\n",
       "      ..\n",
       "495    1\n",
       "496    1\n",
       "497    0\n",
       "498    0\n",
       "499    1\n",
       "Name: class, Length: 500, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating another variable to save the features except target column\n",
    "features = df.drop('class', axis=1)\n",
    "features\n",
    "\n",
    "## naming the response variable as target\n",
    "target = df['class']\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb35491a",
   "metadata": {},
   "source": [
    "## 2) Pipeline to implement a scaler and MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef0b855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 375 size of test set: 125\n",
      "MLPClassifier(hidden_layer_sizes=(2,), learning_rate='adaptive', max_iter=3000)\n",
      "model score: 0.920\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(2, 2), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.656\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5,), learning_rate='adaptive', max_iter=1000)\n",
      "model score: 0.928\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5, 2), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.920\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5, 5), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.936\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(5, 10), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.920\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(10,), learning_rate='adaptive', max_iter=1000)\n",
      "model score: 0.928\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(10, 2), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.928\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(10, 5), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.928\n",
      "---------- \n",
      "\n",
      "MLPClassifier(hidden_layer_sizes=(10, 10), learning_rate='adaptive',\n",
      "              max_iter=1000)\n",
      "model score: 0.952\n",
      "---------- \n",
      "\n",
      "Best score for R2: 0.95\n",
      "Best parameters: MLPClassifier(hidden_layer_sizes=(10, 10), learning_rate='adaptive',\n",
      "              max_iter=1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "print(\"Size of training set: {} size of test set: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "#  MLP classifier with different configuration settings for dataset\n",
    "clfs = [\n",
    "MLPClassifier(hidden_layer_sizes=(2,),learning_rate='adaptive'\n",
    "                   , max_iter=3000),\n",
    "MLPClassifier(hidden_layer_sizes=(2,2),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(5,),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(5,2),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(5,5),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(5,10),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(10,),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(10,2),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(10,5),learning_rate='adaptive'\n",
    "                   , max_iter=1000),\n",
    "MLPClassifier(hidden_layer_sizes=(10,10),learning_rate='adaptive'\n",
    "                   , max_iter=1000)\n",
    "                         ] \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "# list of classifier names\n",
    "names = [\"ann_1\",\"ann_2\",\"ann_3\",\"ann_4\",\"ann_5\",\"ann_6\",\"ann_7\",\"ann_8\",\"ann_9\",\"ann_10\"]\n",
    "\n",
    "# list of scores from the models\n",
    "scores = []\n",
    "\n",
    "pipes = []  \n",
    "\n",
    "best_score = 0\n",
    "\n",
    "# pipeline to implement a scaler and MLP classifier and loop to find the best parameter\n",
    "for clf in clfs:\n",
    "    pipe = Pipeline(steps=[(\"scaling\", StandardScaler()),('classifier', clf)\n",
    "    ])\n",
    "    pipe.fit(X_train, Y_train)\n",
    "    pipes.append(pipe) # add the pipe so that we can use later\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "    print(clf)\n",
    "    score = pipe.score(X_test, Y_test)\n",
    "    scores.append(score)\n",
    "    print(\"model score: %.3f\" % score)\n",
    "    print(\"---------- \\n\")\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "    if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = clf\n",
    "            \n",
    "print(\"Best score for R2: {:.2f}\".format(best_score))\n",
    "# printing the best parameter\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "\n",
    "\n",
    "tuned_y_pred = best_parameters.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4fbd2",
   "metadata": {},
   "source": [
    "## 3) Confusin Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5050a41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  0  2]\n",
      " [ 7 30  0]\n",
      " [ 1  0 39]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(Y_test, tuned_y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c9218",
   "metadata": {},
   "source": [
    "From our confusion matrix, we can see that for class 0, 46 predictions, which are predicted correctly and we have (30+0+39+0), 69 predictions where model correctly predicts the negative classes. We can see that for class 1, 30 predictions, which are predicted correctly and we have (46+2+39+1), 88 predictions where model correctly predicts the negative classes. Fro class 2, 39 predictions, which are predicted correctly and we have (46+7+30+0), 83 predictions where model correctly predicts the negative classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3bfd8",
   "metadata": {},
   "source": [
    "## 4) Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c03613bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.85      0.96      0.90        48\n",
      "     class 1       1.00      0.81      0.90        37\n",
      "     class 2       0.95      0.97      0.96        40\n",
      "\n",
      "    accuracy                           0.92       125\n",
      "   macro avg       0.93      0.91      0.92       125\n",
      "weighted avg       0.93      0.92      0.92       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, tuned_y_pred, target_names=['class 0', 'class 1', 'class 2']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d89b99",
   "metadata": {},
   "source": [
    "From here, Performance for class 0 is better with regard to recall, which is 96%, performance for class 1 is better with regard to precision, which is 100% respectively in our case. Moreover, performance for class 3 is better with regards to f1-score, which is 96%. Also, our accuracy is 91%, which means our model is 92% accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
